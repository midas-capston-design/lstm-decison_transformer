# ì§€ìê¸° ê¸°ë°˜ LSTM ì‹¤ë‚´ ìœ„ì¹˜ ì¶”ì • ì‹œìŠ¤í…œ í”„ë¡œì íŠ¸

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

### ëª©ì 
ê±´ë¬¼ ë‚´ë¶€ì—ì„œ ìŠ¤ë§ˆíŠ¸í°ì˜ ì§€ìê¸° ì„¼ì„œë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ìœ„ì¹˜ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì •í•˜ëŠ” ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì‹¤ë‚´ ìœ„ì¹˜ ì¶”ì • ì‹œìŠ¤í…œ ê°œë°œ

### í•µì‹¬ ì•„ì´ë””ì–´
- ê±´ë¬¼ ë‚´ ê° ìœ„ì¹˜ë§ˆë‹¤ ê³ ìœ í•œ ì§€ìê¸° íŒ¨í„´ì´ ì¡´ì¬
- ì‚¬ìš©ìê°€ ê±¸ì–´ê°ˆ ë•Œ ì¸¡ì •ë˜ëŠ” ì§€ìê¸° ê°’ì˜ ì‹œí€€ìŠ¤ëŠ” ìœ„ì¹˜ë³„ë¡œ ë…íŠ¹í•œ íŒ¨í„´ì„ í˜•ì„±
- LSTM ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ì‹œê°„ì  íŒ¨í„´ì„ í•™ìŠµí•˜ê³  ìœ„ì¹˜ë¥¼ ë¶„ë¥˜

### ê¸°ìˆ  ìŠ¤íƒ
- **ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬**: TensorFlow / Keras
- **ë°ì´í„° ìˆ˜ì§‘**: ìŠ¤ë§ˆíŠ¸í° (Android/iOS)
- **ì„¼ì„œ**: 3ì¶• ì§€ìê¸° ì„¼ì„œ (Magnetometer)
- **ëª¨ë¸ ì•„í‚¤í…ì²˜**: LSTM (Long Short-Term Memory)

---

## ğŸ¯ ë¬¸ì œ ì •ì˜

### ì ‘ê·¼ ë°©ì‹: ë¶„ë¥˜ ë¬¸ì œ (Classification)

ê±´ë¬¼ ë‚´ë¶€ ê³µê°„ì„ ì—¬ëŸ¬ ê°œì˜ ìœ„ì¹˜(Location)ë¡œ ë¶„í• í•˜ê³ , í˜„ì¬ ì¸¡ì •ë˜ëŠ” ì§€ìê¸° ì‹œí€€ìŠ¤ê°€ ì–´ëŠ ìœ„ì¹˜ì— í•´ë‹¹í•˜ëŠ”ì§€ ë¶„ë¥˜í•˜ëŠ” ë¬¸ì œë¡œ ì •ì˜

### ì…ë ¥ (Input)
```
í˜•íƒœ: (batch_size, sequence_length, features)

êµ¬ì²´ì  ì˜ˆì‹œ:
- batch_size: 32 (í•œ ë²ˆì— í•™ìŠµí•  ìƒ˜í”Œ ìˆ˜)
- sequence_length: 20 (ì—°ì†ëœ ì¸¡ì •ê°’ ê°œìˆ˜)
- features: 3 (Bx, By, Bz - 3ì¶• ì§€ìê¸° ê°’)

ìµœì¢… ì…ë ¥ shape: (32, 20, 3)
```

#### ì…ë ¥ ë°ì´í„° êµ¬ì„±
```python
# í•˜ë‚˜ì˜ ìƒ˜í”Œ ì˜ˆì‹œ (20ê°œì˜ ì—°ì†ëœ 3ì°¨ì› ì§€ìê¸° ì¸¡ì •ê°’)
sample = [
    [45.2, 23.1, -18.5],  # t=0: [Bx, By, Bz] (ë‹¨ìœ„: Î¼T)
    [45.5, 23.3, -18.2],  # t=1
    [45.8, 23.5, -17.9],  # t=2
    ...
    [47.1, 24.2, -16.8]   # t=19
]
```

### ì¶œë ¥ (Output)
```
í˜•íƒœ: (batch_size, num_locations)

êµ¬ì²´ì  ì˜ˆì‹œ:
- batch_size: 32
- num_locations: 50 (ê±´ë¬¼ì„ 50ê°œ ìœ„ì¹˜ë¡œ ë¶„í• í•œ ê²½ìš°)

ìµœì¢… ì¶œë ¥ shape: (32, 50)
```

#### ì¶œë ¥ ë°ì´í„° êµ¬ì„± (One-hot Encoding)
```python
# í˜„ì¬ ìœ„ì¹˜ê°€ 15ë²ˆ ìœ„ì¹˜ë¼ë©´
output = [0, 0, 0, ..., 1, 0, ..., 0]  # 50ê°œ ì¤‘ 15ë²ˆì§¸ë§Œ 1
```

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 1. ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°

```
[ë°ì´í„° ìˆ˜ì§‘] â†’ [ì „ì²˜ë¦¬] â†’ [LSTM ëª¨ë¸] â†’ [ìœ„ì¹˜ ì˜ˆì¸¡]
     â†“            â†“           â†“            â†“
  ìŠ¤ë§ˆíŠ¸í°     ì •ê·œí™”      í•™ìŠµ/ì˜ˆì¸¡     ìœ„ì¹˜ ì¶œë ¥
   ì„¼ì„œ        ìœˆë„ìš°      ë¶„ë¥˜ê¸°
```

### 2. LSTM ëª¨ë¸ ì•„í‚¤í…ì²˜

```python
import tensorflow as tf
from tensorflow import keras

model = keras.Sequential([
    # ì…ë ¥ì¸µ: (batch_size, 20, 3)
    keras.layers.Input(shape=(20, 3)),
    
    # LSTM ë ˆì´ì–´ 1
    keras.layers.LSTM(40, return_sequences=True),
    
    # LSTM ë ˆì´ì–´ 2
    keras.layers.LSTM(40, return_sequences=True),
    
    # LSTM ë ˆì´ì–´ 3
    keras.layers.LSTM(40, return_sequences=True),
    
    # LSTM ë ˆì´ì–´ 4 (ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ë§Œ ì¶œë ¥)
    keras.layers.LSTM(40, return_sequences=False),
    
    # ì¶œë ¥ì¸µ: Softmaxë¥¼ ì‚¬ìš©í•œ ë¶„ë¥˜
    keras.layers.Dense(50, activation='softmax')
])

# ëª¨ë¸ ì»´íŒŒì¼
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
```

### 3. ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì • ê·¼ê±°

| íŒŒë¼ë¯¸í„° | ì„¤ì •ê°’ | ê·¼ê±° |
|---------|--------|------|
| LSTM ë ˆì´ì–´ ìˆ˜ | 4ê°œ | ê´€ë ¨ ì—°êµ¬ì—ì„œ 4ê°œ ë ˆì´ì–´ê°€ ìµœì ì˜ ì •í™•ë„ì™€ í•™ìŠµ ì‹œê°„ ê· í˜• ì œê³µ |
| íˆë“  ìœ ë‹› ìˆ˜ | 40ê°œ | ì¶©ë¶„í•œ íŠ¹ì§• ì¶”ì¶œ ëŠ¥ë ¥ê³¼ ê³¼ì í•© ë°©ì§€ ê· í˜• |
| Sequence Length | 20-30ê°œ | ìœ„ì¹˜ë³„ íŒ¨í„´ì„ ì¸ì‹í•˜ê¸°ì— ì¶©ë¶„í•œ ì‹œê°„ì  ì •ë³´ |
| í•™ìŠµ ì—í­ | 100-200íšŒ | ì†ì‹¤ í•¨ìˆ˜ê°€ ìˆ˜ë ´í•˜ëŠ” ì‹œì  |

---

## ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ë° ì¤€ë¹„

### 1. ê±´ë¬¼ ê³µê°„ ë¶„í• 

```
ì˜ˆì‹œ: ê±´ë¬¼ 1ì¸µì„ 5Ã—10 ê·¸ë¦¬ë“œë¡œ ë¶„í• 
- ì´ ìœ„ì¹˜ ìˆ˜: 50ê°œ
- ê° ìœ„ì¹˜ í¬ê¸°: 2m Ã— 2m
- ìœ„ì¹˜ ë¼ë²¨: Location 0 ~ Location 49
```

```
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ L0  â”‚ L1  â”‚ L2  â”‚ L3  â”‚ L4  â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚ L5  â”‚ L6  â”‚ L7  â”‚ L8  â”‚ L9  â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚ L10 â”‚ L11 â”‚ L12 â”‚ L13 â”‚ L14 â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
   ... (ì´ 10í–‰)
```

### 2. ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œí† ì½œ

#### ìˆ˜ì§‘ ë„êµ¬
- ìŠ¤ë§ˆíŠ¸í° (Android/iOS)
- ì§€ìê¸° ì„¼ì„œ ì•± (ì˜ˆ: Sensor Logger)

#### ìˆ˜ì§‘ ë°©ë²•
```
1. ê° ìœ„ì¹˜ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
   - ê° ìœ„ì¹˜ë‹¹ ìµœì†Œ 200ê°œ ìƒ˜í”Œ
   - ë‹¤ì–‘í•œ ë°©í–¥ì—ì„œ ìˆ˜ì§‘ (ë™ì„œë‚¨ë¶)
   - ì¼ì •í•œ ì†ë„ë¡œ ê±·ê¸° (ì•½ 1m/s)

2. ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜
   - 10Hz ~ 50Hz (ì´ˆë‹¹ 10~50íšŒ ì¸¡ì •)
   - ê¶Œì¥: 20Hz

3. ìˆ˜ì§‘ ì‹œë‚˜ë¦¬ì˜¤
   - ìœ„ì¹˜ A â†’ ìœ„ì¹˜ Bë¡œ ì´ë™í•˜ë©° ì—°ì† ì¸¡ì •
   - ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œí€€ìŠ¤ ìƒì„±
```

#### ë°ì´í„° ë¼ë²¨ë§
```python
# ì˜ˆì‹œ: Location 15ë¥¼ ì§€ë‚˜ëŠ” ê²½ë¡œì—ì„œ ìˆ˜ì§‘
ë°ì´í„°: [ì¸¡ì •ê°’ ì‹œí€€ìŠ¤]
ë¼ë²¨: 15

# ì €ì¥ í˜•ì‹
{
    "sequence": [[45.2, 23.1, -18.5], [45.5, 23.3, -18.2], ...],
    "label": 15,
    "timestamp": "2025-11-09 10:30:00",
    "location_name": "ë³µë„_A_15"
}
```

### 3. ë°ì´í„°ì…‹ êµ¬ì„±

```python
# ì „ì²´ ë°ì´í„°ì…‹ ì˜ˆì‹œ
ì´ ìƒ˜í”Œ ìˆ˜: 10,000ê°œ
- ê° ìœ„ì¹˜ë‹¹ 200ê°œ ìƒ˜í”Œ Ã— 50ê°œ ìœ„ì¹˜

ë°ì´í„° ë¶„í• :
- í•™ìŠµ ë°ì´í„° (Training): 70% = 7,000ê°œ
- ê²€ì¦ ë°ì´í„° (Validation): 15% = 1,500ê°œ
- í…ŒìŠ¤íŠ¸ ë°ì´í„° (Test): 15% = 1,500ê°œ

í˜•íƒœ:
X_train.shape = (7000, 20, 3)
y_train.shape = (7000, 50)  # one-hot encoded

X_val.shape = (1500, 20, 3)
y_val.shape = (1500, 50)

X_test.shape = (1500, 20, 3)
y_test.shape = (1500, 50)
```

---

## ğŸ’» êµ¬í˜„ ë‹¨ê³„

### Phase 1: ë°ì´í„° ìˆ˜ì§‘

```python
# 1. ìŠ¤ë§ˆíŠ¸í°ìœ¼ë¡œ ì§€ìê¸° ë°ì´í„° ìˆ˜ì§‘
# 2. CSV íŒŒì¼ë¡œ ì €ì¥

# ë°ì´í„° í˜•ì‹:
# timestamp, bx, by, bz, location_id
# 2025-11-09 10:30:00.000, 45.2, 23.1, -18.5, 15
# 2025-11-09 10:30:00.050, 45.5, 23.3, -18.2, 15
```

### Phase 2: ë°ì´í„° ì „ì²˜ë¦¬

```python
import numpy as np
import pandas as pd

def create_sequences(data, sequence_length=20):
    """
    ì›ì‹œ ë°ì´í„°ë¥¼ LSTM ì…ë ¥ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
    
    Args:
        data: DataFrame with columns [bx, by, bz, location_id]
        sequence_length: ì‹œí€€ìŠ¤ ê¸¸ì´
    
    Returns:
        X: (num_samples, sequence_length, 3)
        y: (num_samples, num_locations) - one-hot encoded
    """
    sequences = []
    labels = []
    
    for i in range(len(data) - sequence_length):
        # 20ê°œì˜ ì—°ì†ëœ ì¸¡ì •ê°’ ì¶”ì¶œ
        seq = data.iloc[i:i+sequence_length][['bx', 'by', 'bz']].values
        label = data.iloc[i+sequence_length-1]['location_id']
        
        sequences.append(seq)
        labels.append(label)
    
    X = np.array(sequences)
    y = np.array(labels)
    
    # One-hot encoding
    num_locations = len(np.unique(y))
    y_onehot = np.zeros((len(y), num_locations))
    y_onehot[np.arange(len(y)), y] = 1
    
    return X, y_onehot

# ë°ì´í„° ì •ê·œí™”
def normalize_data(X):
    """
    ì§€ìê¸° ë°ì´í„° ì •ê·œí™”
    """
    mean = X.mean(axis=(0, 1))
    std = X.std(axis=(0, 1))
    
    X_normalized = (X - mean) / std
    
    return X_normalized, mean, std

# ì‚¬ìš© ì˜ˆì‹œ
df = pd.read_csv('magnetic_data.csv')
X, y = create_sequences(df, sequence_length=20)
X_norm, mean, std = normalize_data(X)
```

### Phase 3: ëª¨ë¸ í•™ìŠµ

```python
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split

# ë°ì´í„° ë¶„í• 
X_train, X_temp, y_train, y_temp = train_test_split(
    X_norm, y, test_size=0.3, random_state=42
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42
)

# ëª¨ë¸ êµ¬ì¶•
model = keras.Sequential([
    keras.layers.Input(shape=(20, 3)),
    keras.layers.LSTM(40, return_sequences=True),
    keras.layers.LSTM(40, return_sequences=True),
    keras.layers.LSTM(40, return_sequences=True),
    keras.layers.LSTM(40, return_sequences=False),
    keras.layers.Dense(50, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# ì½œë°± ì„¤ì •
callbacks = [
    keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=20,
        restore_best_weights=True
    ),
    keras.callbacks.ModelCheckpoint(
        'best_model.h5',
        monitor='val_accuracy',
        save_best_only=True
    )
]

# í•™ìŠµ
history = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=200,
    validation_data=(X_val, y_val),
    callbacks=callbacks,
    verbose=1
)

# í‰ê°€
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy * 100:.2f}%")
```

### Phase 4: ì‹¤ì‹œê°„ ì˜ˆì¸¡

```python
def predict_location(model, new_sequence, mean, std, location_names):
    """
    ì‹¤ì‹œê°„ ìœ„ì¹˜ ì˜ˆì¸¡
    
    Args:
        model: í•™ìŠµëœ LSTM ëª¨ë¸
        new_sequence: (20, 3) í˜•íƒœì˜ ìƒˆë¡œìš´ ì§€ìê¸° ì‹œí€€ìŠ¤
        mean, std: ì •ê·œí™” íŒŒë¼ë¯¸í„°
        location_names: ìœ„ì¹˜ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        predicted_location: ì˜ˆì¸¡ëœ ìœ„ì¹˜
        confidence: ì˜ˆì¸¡ ì‹ ë¢°ë„
    """
    # ì •ê·œí™”
    new_sequence = (new_sequence - mean) / std
    
    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    new_sequence = np.expand_dims(new_sequence, axis=0)
    
    # ì˜ˆì¸¡
    prediction = model.predict(new_sequence, verbose=0)
    
    # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ìœ„ì¹˜
    predicted_idx = np.argmax(prediction[0])
    confidence = prediction[0][predicted_idx]
    
    predicted_location = location_names[predicted_idx]
    
    return predicted_location, confidence

# ì‚¬ìš© ì˜ˆì‹œ
location_names = [f"Location_{i}" for i in range(50)]

# ìƒˆë¡œìš´ 20ê°œì˜ ì¸¡ì •ê°’ (ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ì§‘)
new_measurements = np.array([
    [46.1, 24.0, -17.2],
    [46.3, 24.1, -17.0],
    # ... 18ê°œ ë”
])

location, conf = predict_location(model, new_measurements, mean, std, location_names)
print(f"ì˜ˆì¸¡ ìœ„ì¹˜: {location}, ì‹ ë¢°ë„: {conf*100:.2f}%")
```

---

## ğŸ“ˆ ì„±ëŠ¥ í‰ê°€

### í‰ê°€ ì§€í‘œ

1. **ì •í™•ë„ (Accuracy)**
   - ì „ì²´ ì˜ˆì¸¡ ì¤‘ ì •í™•í•œ ì˜ˆì¸¡ì˜ ë¹„ìœ¨
   - ëª©í‘œ: 85% ì´ìƒ

2. **ìœ„ì¹˜ë³„ ì •í™•ë„**
   - ê° ìœ„ì¹˜ì—ì„œì˜ ë¶„ë¥˜ ì •í™•ë„
   - í˜¼ë™ í–‰ë ¬(Confusion Matrix)ë¡œ ì‹œê°í™”

3. **í‰ê·  ê±°ë¦¬ ì˜¤ì°¨**
   - ì˜ˆì¸¡ ìœ„ì¹˜ì™€ ì‹¤ì œ ìœ„ì¹˜ ê°„ì˜ ë¬¼ë¦¬ì  ê±°ë¦¬
   - ëª©í‘œ: 2m ì´í•˜

### ì„±ëŠ¥ í–¥ìƒ ê¸°ë²•

```python
# 1. ë°ì´í„° ì¦ê°• (Data Augmentation)
def augment_sequence(sequence, noise_level=0.1):
    """ì§€ìê¸° ë°ì´í„°ì— ë…¸ì´ì¦ˆ ì¶”ê°€"""
    noise = np.random.normal(0, noise_level, sequence.shape)
    return sequence + noise

# 2. ì•™ìƒë¸” ë°©ë²•
# ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ê²°í•©í•˜ì—¬ ì •í™•ë„ í–¥ìƒ

# 3. í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼
# WiFi RSS, ê°€ì†ë„ê³„ ë“± ì¶”ê°€ ì„¼ì„œ ë°ì´í„° ê²°í•©
```

---

## ğŸš€ ë°°í¬ ë° ì‹¤ì‚¬ìš©

### ëª¨ë°”ì¼ ì•± í†µí•©

```python
# TensorFlow Liteë¡œ ëª¨ë¸ ë³€í™˜
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# ëª¨ë¸ ì €ì¥
with open('indoor_localization.tflite', 'wb') as f:
    f.write(tflite_model)
```

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **ìŠ¤ë§ˆíŠ¸í°**: ì§€ìê¸° ì„¼ì„œ íƒ‘ì¬
- **ìµœì†Œ Android ë²„ì „**: 6.0 ì´ìƒ
- **ìµœì†Œ iOS ë²„ì „**: 12.0 ì´ìƒ
- **ëª¨ë¸ í¬ê¸°**: ì•½ 500KB
- **ì˜ˆì¸¡ ì‹œê°„**: 50ms ì´í•˜

---

## ğŸ”§ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 1. ë‚®ì€ ì •í™•ë„
```
ì›ì¸:
- ë°ì´í„° ìˆ˜ì§‘ ë¶€ì¡±
- ìœ„ì¹˜ê°€ ë„ˆë¬´ ë§ì´ ë¶„í• ë¨
- ì§€ìê¸° ê°„ì„­

í•´ê²°:
- ê° ìœ„ì¹˜ë‹¹ ìƒ˜í”Œ ìˆ˜ ì¦ê°€ (200ê°œ â†’ 500ê°œ)
- ìœ„ì¹˜ ê°œìˆ˜ ì¤„ì´ê¸° (50ê°œ â†’ 30ê°œ)
- ê¸ˆì† ë¬¼ì²´ê°€ ì ì€ í™˜ê²½ ì„ íƒ
```

#### 2. ê³¼ì í•© (Overfitting)
```
ì›ì¸:
- í•™ìŠµ ë°ì´í„° ê³¼ë‹¤ í•™ìŠµ

í•´ê²°:
- Dropout ë ˆì´ì–´ ì¶”ê°€
- ì •ê·œí™” ì ìš© (L1, L2)
- Early Stopping ì‚¬ìš©
```

#### 3. ìœ„ì¹˜ ëª¨í˜¸ì„±
```
ì›ì¸:
- ì—¬ëŸ¬ ìœ„ì¹˜ê°€ ìœ ì‚¬í•œ ì§€ìê¸° íŒ¨í„´

í•´ê²°:
- Sequence Length ëŠ˜ë¦¬ê¸° (20 â†’ 30)
- Multi-scale TCN ì¶”ê°€
- ë°©í–¥ ì •ë³´ í†µí•©
```

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

### ì£¼ìš” ë…¼ë¬¸

1. **"Indoor Localization Using Smartphone Magnetic with Multi-Scale TCN and LSTM"**
   - Multi-scale TCNê³¼ LSTM ê²°í•© ì•„í‚¤í…ì²˜
   - ë‹¤ì–‘í•œ ì´ë™ ì†ë„ ëŒ€ì‘

2. **"DeepML: Deep LSTM for Indoor Localization with Smartphone Magnetic and Light Sensors"**
   - ì§€ìê¸° + ì¡°ë„ ì„¼ì„œ ìœµí•©
   - 4-layer LSTM ì•„í‚¤í…ì²˜

3. **"A Hierarchical LSTM-Based Indoor Geomagnetic Localization Algorithm"**
   - ê³„ì¸µì  LSTM êµ¬ì¡°
   - ìœ„ì¹˜ ëª¨í˜¸ì„± í•´ê²°

### í•µì‹¬ ì¸ì‚¬ì´íŠ¸

- **ì‹œê°„ì  íŒ¨í„´ì˜ ì¤‘ìš”ì„±**: ë‹¨ì¼ ì¸¡ì •ê°’ì´ ì•„ë‹Œ ì‹œí€€ìŠ¤ê°€ í•µì‹¬
- **LSTMì˜ íš¨ê³¼**: ì‹œê°„ì  ì˜ì¡´ì„±ì„ ì˜ í¬ì°©
- **í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼**: ë‹¤ì¤‘ ì„¼ì„œ ìœµí•©ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### í”„ë¡œì íŠ¸ ì§„í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **1ë‹¨ê³„: ê³„íš ë° ì¤€ë¹„**
  - [ ] ê±´ë¬¼ í‰ë©´ë„ í™•ë³´
  - [ ] ìœ„ì¹˜ ë¶„í•  ê³„íš ìˆ˜ë¦½
  - [ ] ë°ì´í„° ìˆ˜ì§‘ ë„êµ¬ ì¤€ë¹„

- [ ] **2ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘**
  - [ ] ê° ìœ„ì¹˜ì—ì„œ 200ê°œ ì´ìƒ ìƒ˜í”Œ ìˆ˜ì§‘
  - [ ] ë‹¤ì–‘í•œ ë°©í–¥ì—ì„œ ìˆ˜ì§‘
  - [ ] ë°ì´í„° í’ˆì§ˆ í™•ì¸

- [ ] **3ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬**
  - [ ] ì‹œí€€ìŠ¤ ìƒì„± ì½”ë“œ ì‘ì„±
  - [ ] ì •ê·œí™” ì ìš©
  - [ ] Train/Val/Test ë¶„í• 

- [ ] **4ë‹¨ê³„: ëª¨ë¸ ê°œë°œ**
  - [ ] LSTM ëª¨ë¸ êµ¬ì¶•
  - [ ] í•™ìŠµ ë° ê²€ì¦
  - [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

- [ ] **5ë‹¨ê³„: í‰ê°€ ë° ìµœì í™”**
  - [ ] í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
  - [ ] ì„±ëŠ¥ ë¶„ì„
  - [ ] ê°œì„  ì‘ì—…

- [ ] **6ë‹¨ê³„: ë°°í¬**
  - [ ] ëª¨ë¸ ê²½ëŸ‰í™” (TFLite)
  - [ ] ëª¨ë°”ì¼ ì•± í†µí•©
  - [ ] ì‹¤ì‚¬ìš© í…ŒìŠ¤íŠ¸

---

## ğŸ”® í–¥í›„ ê°œì„  ë°©í–¥

### ë‹¨ê¸° ê°œì„ 
1. **Multi-scale TCN ì¶”ê°€**
   - ë‹¤ì–‘í•œ ì´ë™ ì†ë„ ëŒ€ì‘
   - íŠ¹ì§• ì°¨ì› í™•ì¥

2. **ì„¼ì„œ ìœµí•©**
   - WiFi RSS ì¶”ê°€
   - ì¡°ë„ ì„¼ì„œ í™œìš©

3. **ë°©í–¥ ì •ë³´ í†µí•©**
   - ìì´ë¡œìŠ¤ì½”í”„ ë°ì´í„° í™œìš©
   - ë°©í–¥ë³„ ëª¨ë¸ í•™ìŠµ

### ì¥ê¸° ê°œì„ 
1. **ì „ì´ í•™ìŠµ (Transfer Learning)**
   - ë‹¤ë¥¸ ê±´ë¬¼ì— ëª¨ë¸ ì¬ì‚¬ìš©
   - ì ì€ ë°ì´í„°ë¡œ ë¹ ë¥¸ ì ì‘

2. **ì‹¤ì‹œê°„ ë§µí•‘**
   - SLAM ê¸°ë²• í†µí•©
   - ë™ì  í™˜ê²½ ëŒ€ì‘

3. **ì‚¬ìš©ì ê²½í—˜ ìµœì í™”**
   - ë°°í„°ë¦¬ ì†Œëª¨ ìµœì†Œí™”
   - ì˜ˆì¸¡ ì†ë„ í–¥ìƒ

---

## ğŸ“ ë¬¸ì˜ ë° ì§€ì›

### ê°œë°œ í™˜ê²½ ì„¤ì • ë¬¸ì˜
- Python ë²„ì „: 3.8 ì´ìƒ
- TensorFlow ë²„ì „: 2.10 ì´ìƒ
- í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬: numpy, pandas, scikit-learn

### ì¶”ê°€ ìë£Œ
- [TensorFlow ê³µì‹ ë¬¸ì„œ](https://www.tensorflow.org/)
- [LSTM íŠœí† ë¦¬ì–¼](https://www.tensorflow.org/guide/keras/rnn)
- [ì‹¤ë‚´ ìœ„ì¹˜ ì¶”ì • ë¦¬ë·° ë…¼ë¬¸](https://link.springer.com/)

---

**ë¬¸ì„œ ë²„ì „**: 1.0  
**ìµœì¢… ìˆ˜ì •ì¼**: 2025-11-09  
**ì‘ì„±ì**: Claude AI Assistant
