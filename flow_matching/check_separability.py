#!/usr/bin/env python3
"""
ë°ì´í„° íŒë³„ë ¥ ì²´í¬: ìœ„ì¹˜ë³„ë¡œ ì„¼ì„œ íŒ¨í„´ì´ ê³ ìœ í•œê°€?
"""
import numpy as np
from pathlib import Path
from collections import defaultdict
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # For saving plots without display

print("="*70)
print("ğŸ” ë°ì´í„° íŒë³„ë ¥ ì²´í¬")
print("="*70)

# ë°ì´í„° ë¡œë“œ (ì›ë³¸ë§Œ ì‚¬ìš© - ì¦ê°• ì œì™¸)
data_dir = Path(__file__).resolve().parent / 'processed_data_flow_matching'
states_train_all = np.load(data_dir / 'states_train.npy')
coords_train_all = np.load(data_dir / 'coords_train.npy')

# ì›ë³¸ë§Œ ì‚¬ìš© (Train: 27,243ê°œ = 18,162 ì›ë³¸ + 9,081 ì¦ê°•)
# ì¦ê°•ì€ ì¸ìœ„ì  íŒ¨í„´ì´ë¯€ë¡œ ì‹¤ì œ ì„¼ì„œ ë°ì´í„°ì˜ ë¶„ë¦¬ë„ë§Œ í…ŒìŠ¤íŠ¸
N_ORIGINAL = 18162
states_train = states_train_all[:N_ORIGINAL]
coords_train = coords_train_all[:N_ORIGINAL]

print(f"\nTrain (ì „ì²´): {len(states_train_all):,}ê°œ")
print(f"Train (ì›ë³¸ë§Œ): {len(states_train):,}ê°œ - ì¦ê°• ì œì™¸í•˜ê³  í…ŒìŠ¤íŠ¸")

# Grid 0.9m ê¸°ì¤€ìœ¼ë¡œ ìœ„ì¹˜ ê·¸ë£¹í™”
def coord_to_grid(x, y, grid_size=0.9):
    """ì¢Œí‘œë¥¼ grid IDë¡œ"""
    # ì—­ì •ê·œí™” (-1~1 â†’ ì‹¤ì œ ì¢Œí‘œ)
    # ê±´ë¬¼ ë²”ìœ„ ì•½ 85.5m x 18m
    x_real = (x + 1) / 2 * 85.5
    y_real = (y + 1) / 2 * 18

    grid_x = int(x_real / grid_size)
    grid_y = int(y_real / grid_size)
    return (grid_x, grid_y)

# ìœ„ì¹˜ë³„ ìƒ˜í”Œ ê·¸ë£¹í™”
location_samples = defaultdict(list)

print("\n[1/3] ìœ„ì¹˜ë³„ ìƒ˜í”Œ ê·¸ë£¹í™”...")
for i in tqdm(range(len(coords_train))):
    grid = coord_to_grid(coords_train[i, 0], coords_train[i, 1])
    location_samples[grid].append(i)

# ìƒ˜í”Œ 2ê°œ ì´ìƒì¸ ìœ„ì¹˜ë§Œ
locations_with_multiple = {k: v for k, v in location_samples.items() if len(v) >= 2}

print(f"\ní†µê³„:")
print(f"  ì´ ìœ„ì¹˜: {len(location_samples)}ê°œ")
print(f"  ìƒ˜í”Œ 2ê°œ ì´ìƒ ìœ„ì¹˜: {len(locations_with_multiple)}ê°œ")
print(f"  í‰ê·  ìƒ˜í”Œ/ìœ„ì¹˜: {len(states_train)/len(location_samples):.1f}ê°œ")

# ìƒ˜í”Œ ë§ì€ ìƒìœ„ 10ê°œ ìœ„ì¹˜
top_locations = sorted(location_samples.items(), key=lambda x: len(x[1]), reverse=True)[:10]
print(f"\nìƒ˜í”Œ ë§ì€ ìœ„ì¹˜ TOP 10:")
for i, (loc, samples) in enumerate(top_locations, 1):
    print(f"  {i}. Grid {loc}: {len(samples)}ê°œ ìƒ˜í”Œ")

print("\n[2/3] ê°™ì€ ìœ„ì¹˜ vs ë‹¤ë¥¸ ìœ„ì¹˜ ê±°ë¦¬ ê³„ì‚°...")

# ì„¼ì„œ ê±°ë¦¬ í•¨ìˆ˜
def sensor_distance(s1, s2):
    """ë‘ ì„¼ì„œ ì‹œí€€ìŠ¤ì˜ ê±°ë¦¬"""
    return np.linalg.norm(s1 - s2)

# ìƒ˜í”Œ ë§ì€ ìœ„ì¹˜ 5ê°œë¡œ í…ŒìŠ¤íŠ¸
test_locations = top_locations[:5]

same_location_distances = []
diff_location_distances = []

for loc, sample_indices in tqdm(test_locations[:5], desc="Computing"):
    # ê°™ì€ ìœ„ì¹˜ ë‚´ ê±°ë¦¬
    if len(sample_indices) >= 2:
        for i in range(min(10, len(sample_indices))):
            for j in range(i+1, min(10, len(sample_indices))):
                idx1, idx2 = sample_indices[i], sample_indices[j]
                dist = sensor_distance(states_train[idx1], states_train[idx2])
                same_location_distances.append(dist)

    # ë‹¤ë¥¸ ìœ„ì¹˜ì™€ì˜ ê±°ë¦¬
    other_loc, other_indices = test_locations[1] if loc == test_locations[0][0] else test_locations[0]
    for i in range(min(10, len(sample_indices))):
        for j in range(min(10, len(other_indices))):
            idx1 = sample_indices[i]
            idx2 = other_indices[j]
            dist = sensor_distance(states_train[idx1], states_train[idx2])
            diff_location_distances.append(dist)

same_location_distances = np.array(same_location_distances)
diff_location_distances = np.array(diff_location_distances)

print("\n[3/3] ê²°ê³¼ ë¶„ì„:")
print(f"\nğŸ“Š ì„¼ì„œ íŒ¨í„´ ê±°ë¦¬:")
print(f"  ê°™ì€ ìœ„ì¹˜ë¼ë¦¬: í‰ê·  {same_location_distances.mean():.4f} (std {same_location_distances.std():.4f})")
print(f"  ë‹¤ë¥¸ ìœ„ì¹˜ë¼ë¦¬: í‰ê·  {diff_location_distances.mean():.4f} (std {diff_location_distances.std():.4f})")

# íŒë³„ë ¥ ì§€í‘œ
ratio = diff_location_distances.mean() / same_location_distances.mean()
overlap = np.percentile(diff_location_distances, 25) < np.percentile(same_location_distances, 75)

print(f"\nğŸ’¡ íŒë³„ë ¥ ë¶„ì„:")
print(f"  ê±°ë¦¬ ë¹„ìœ¨ (ë‹¤ë¥¸ ìœ„ì¹˜ / ê°™ì€ ìœ„ì¹˜): {ratio:.2f}x")

if ratio > 2.0:
    print(f"  âœ… ë¹„ìœ¨ {ratio:.1f}x â†’ ìœ„ì¹˜ë³„ íŒ¨í„´ êµ¬ë¶„ ê°€ëŠ¥!")
elif ratio > 1.3:
    print(f"  âš ï¸ ë¹„ìœ¨ {ratio:.1f}x â†’ ì–´ëŠì •ë„ êµ¬ë¶„ ê°€ëŠ¥, ì–´ë ¤ì›€")
else:
    print(f"  âŒ ë¹„ìœ¨ {ratio:.1f}x â†’ ìœ„ì¹˜ êµ¬ë¶„ ê±°ì˜ ë¶ˆê°€ëŠ¥!")

if overlap:
    print(f"  âš ï¸ ë¶„í¬ ê²¹ì¹¨ í¼ â†’ ëª¨ë¸ í•™ìŠµ ì–´ë ¤ì›€")
else:
    print(f"  âœ… ë¶„í¬ ë¶„ë¦¬ë¨ â†’ ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥")

print("\n" + "="*70)
if ratio > 1.5:
    print("âœ… ë°ì´í„°ì— ìœ„ì¹˜ ì •ë³´ ìˆìŒ â†’ ëª¨ë¸ ê°œì„  ê°€ëŠ¥")
else:
    print("âŒ ë°ì´í„° ìì²´ ë¬¸ì œ â†’ ì„¼ì„œê°€ ìœ„ì¹˜ êµ¬ë¶„ ëª»í•¨")
print("="*70)

# ì‹œê°í™”
print("\n[4/4] ì‹œê°í™” ìƒì„±...")

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. Distance Distribution Histogram
ax1 = axes[0, 0]
bins = np.linspace(
    min(same_location_distances.min(), diff_location_distances.min()),
    max(same_location_distances.max(), diff_location_distances.max()),
    50
)
ax1.hist(same_location_distances, bins=bins, alpha=0.6, color='blue', label='Same Location', density=True)
ax1.hist(diff_location_distances, bins=bins, alpha=0.6, color='red', label='Different Location', density=True)
ax1.axvline(same_location_distances.mean(), color='blue', linestyle='--', linewidth=2, label=f'Same Mean: {same_location_distances.mean():.2f}')
ax1.axvline(diff_location_distances.mean(), color='red', linestyle='--', linewidth=2, label=f'Diff Mean: {diff_location_distances.mean():.2f}')
ax1.set_xlabel('Sensor Pattern Distance', fontsize=12)
ax1.set_ylabel('Density', fontsize=12)
ax1.set_title('Sensor Pattern Distance Distribution (Original Data)', fontsize=14, fontweight='bold')
ax1.legend(fontsize=10)
ax1.grid(True, alpha=0.3)

# 2. Box Plot
ax2 = axes[0, 1]
data_to_plot = [same_location_distances, diff_location_distances]
bp = ax2.boxplot(data_to_plot, tick_labels=['Same Location', 'Different Location'], patch_artist=True)
bp['boxes'][0].set_facecolor('blue')
bp['boxes'][0].set_alpha(0.6)
bp['boxes'][1].set_facecolor('red')
bp['boxes'][1].set_alpha(0.6)
ax2.set_ylabel('Sensor Pattern Distance', fontsize=12)
ax2.set_title('Distance Comparison (Box Plot)', fontsize=14, fontweight='bold')
ax2.grid(True, alpha=0.3, axis='y')
ax2.text(0.5, 0.95, f'Ratio: {ratio:.2f}x', transform=ax2.transAxes,
         fontsize=14, fontweight='bold', ha='center', va='top',
         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

# 3. Samples per Location Distribution
ax3 = axes[1, 0]
samples_per_location = [len(v) for v in location_samples.values()]
ax3.hist(samples_per_location, bins=30, color='green', alpha=0.7, edgecolor='black')
ax3.axvline(np.mean(samples_per_location), color='red', linestyle='--', linewidth=2,
            label=f'Mean: {np.mean(samples_per_location):.1f}')
ax3.set_xlabel('Samples per Location', fontsize=12)
ax3.set_ylabel('Number of Locations', fontsize=12)
ax3.set_title('Sample Distribution by Location', fontsize=14, fontweight='bold')
ax3.legend(fontsize=10)
ax3.grid(True, alpha=0.3)

# 4. Spatial Location Distribution (2D) - ACTUAL COORDINATES
ax4 = axes[1, 1]
# De-normalize original coordinates to real meters
x_real = (coords_train[:, 0] + 1) / 2 * 85.5
y_real = (coords_train[:, 1] + 1) / 2 * 18

scatter = ax4.scatter(x_real, y_real, s=1, alpha=0.3, c='blue')
ax4.set_xlabel('X Coordinate (m)', fontsize=12)
ax4.set_ylabel('Y Coordinate (m)', fontsize=12)
ax4.set_title('Actual Data Collection Path (Original Coordinates)', fontsize=14, fontweight='bold')
ax4.grid(True, alpha=0.3)
ax4.set_xlim(0, 90)
ax4.set_ylim(-2, 20)
ax4.set_aspect('equal', adjustable='box')

# Add range info
ax4.text(0.02, 0.98, f'X: [{x_real.min():.1f}, {x_real.max():.1f}]m\nY: [{y_real.min():.1f}, {y_real.max():.1f}]m',
         transform=ax4.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.savefig('separability_analysis.png', dpi=150, bbox_inches='tight')
print(f"âœ… ì‹œê°í™” ì €ì¥: separability_analysis.png")

print("\n" + "="*70)
print("ğŸ¯ í•µì‹¬ ìš”ì•½:")
print(f"  - ì´ ìœ„ì¹˜: {len(location_samples)}ê°œ")
print(f"  - í‰ê·  ìƒ˜í”Œ/ìœ„ì¹˜: {len(states_train)/len(location_samples):.1f}ê°œ")
print(f"  - ê°™ì€ ìœ„ì¹˜ ê±°ë¦¬: {same_location_distances.mean():.2f} Â± {same_location_distances.std():.2f}")
print(f"  - ë‹¤ë¥¸ ìœ„ì¹˜ ê±°ë¦¬: {diff_location_distances.mean():.2f} Â± {diff_location_distances.std():.2f}")
print(f"  - ë¶„ë¦¬ë„ ë¹„ìœ¨: {ratio:.2f}x (2.0x ì´ìƒì´ë©´ ìš°ìˆ˜)")
print("="*70)
