#!/usr/bin/env python3
"""
Flow Matching for Magnetic Field Indoor Positioning - Training Script

í•µì‹¬:
- Conditional Flow Matchingìœ¼ë¡œ ì„¼ì„œ â†’ ìœ„ì¹˜ í•™ìŠµ
- 1-2 step inferenceë¡œ ì‹¤ì‹œê°„ ê°€ëŠ¥
- ì™„ì „íˆ ìƒˆë¡œìš´ ì ‘ê·¼ë²• (ë…¼ë¬¸ 0ê°œ)
"""
import numpy as np
import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
import math
from tqdm import tqdm

from model import FlowMatchingLocalization, compute_flow_matching_loss

print("=" * 70)
print("ğŸš€ Flow Matching for Indoor Positioning - Training")
print("=" * 70)

# ============================================================================
# Configuration
# ============================================================================
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"\nì‚¬ìš© ë””ë°”ì´ìŠ¤: {DEVICE}")

CONFIG = {
    # Model
    'sensor_dim': 6,
    'position_dim': 2,
    'd_model': 256,
    'encoder_layers': 4,
    'velocity_layers': 4,
    'n_heads': 8,
    'dropout': 0.1,

    # Training
    'batch_size': 64,
    'learning_rate': 1e-4,
    'weight_decay': 1e-4,
    'epochs': 50,
    'warmup_steps': 2000,

    # Inference
    'inference_steps': 10,  # Can use 1-2 for real-time
}

print("\nì„¤ì •:")
for key, value in CONFIG.items():
    print(f"  {key}: {value}")

# ============================================================================
# Dataset
# ============================================================================
class FlowMatchingDataset(Dataset):
    """
    Flow Matchingìš© ë°ì´í„°ì…‹

    Input: ì„¼ì„œ ì‹œí€€ìŠ¤ (100, 6)
    Target: ë§ˆì§€ë§‰ ìœ„ì¹˜ (2,)
    """
    def __init__(self, states, trajectories):
        """
        Args:
            states: (N, 100, 6) - ì„¼ì„œ ë°ì´í„°
            trajectories: (N, 100, 2) - ê° timestepì˜ ìœ„ì¹˜
        """
        self.states = torch.FloatTensor(states)
        self.positions = torch.FloatTensor(trajectories[:, -1, :])  # ë§ˆì§€ë§‰ ìœ„ì¹˜ë§Œ

    def __len__(self):
        return len(self.states)

    def __getitem__(self, idx):
        return {
            'sensor_data': self.states[idx],      # (100, 6)
            'position': self.positions[idx],       # (2,)
        }

# ============================================================================
# Training
# ============================================================================
def train():
    print("\n[1/6] ë°ì´í„° ë¡œë“œ...")

    data_dir = Path(__file__).parent.parent / 'processed_data_dt'

    states_train = np.load(data_dir / 'states_train.npy')
    traj_train = np.load(data_dir / 'trajectories_train.npy')

    states_val = np.load(data_dir / 'states_val.npy')
    traj_val = np.load(data_dir / 'trajectories_val.npy')

    print(f"  Train: {states_train.shape}")
    print(f"  Val:   {states_val.shape}")

    print("\n[2/6] ë°ì´í„°ì…‹ ìƒì„±...")
    train_dataset = FlowMatchingDataset(states_train, traj_train)
    val_dataset = FlowMatchingDataset(states_val, traj_val)

    train_loader = DataLoader(
        train_dataset,
        batch_size=CONFIG['batch_size'],
        shuffle=True,
        num_workers=0,
        pin_memory=True if DEVICE.type == 'cuda' else False
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=CONFIG['batch_size'],
        shuffle=False,
        num_workers=0,
        pin_memory=True if DEVICE.type == 'cuda' else False
    )

    print(f"  Train batches: {len(train_loader)}")
    print(f"  Val batches: {len(val_loader)}")

    print("\n[3/6] ëª¨ë¸ ì´ˆê¸°í™”...")
    model = FlowMatchingLocalization(
        sensor_dim=CONFIG['sensor_dim'],
        position_dim=CONFIG['position_dim'],
        d_model=CONFIG['d_model'],
        encoder_layers=CONFIG['encoder_layers'],
        velocity_layers=CONFIG['velocity_layers'],
        n_heads=CONFIG['n_heads'],
        dropout=CONFIG['dropout']
    ).to(DEVICE)

    n_params = sum(p.numel() for p in model.parameters())
    print(f"  ì´ íŒŒë¼ë¯¸í„°: {n_params:,}")

    print("\n[4/6] Optimizer & Scheduler...")
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=CONFIG['learning_rate'],
        weight_decay=CONFIG['weight_decay']
    )

    # Cosine annealing with warmup
    def lr_lambda(step):
        if step < CONFIG['warmup_steps']:
            return step / CONFIG['warmup_steps']
        else:
            progress = (step - CONFIG['warmup_steps']) / (CONFIG['epochs'] * len(train_loader) - CONFIG['warmup_steps'])
            return 0.5 * (1 + math.cos(math.pi * progress))

    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)

    print("\n[5/6] í•™ìŠµ ì‹œì‘...")
    print(f"  Epochs: {CONFIG['epochs']}")
    print(f"  Batch size: {CONFIG['batch_size']}")

    best_val_loss = float('inf')

    for epoch in range(CONFIG['epochs']):
        # ========== Training ==========
        model.train()
        train_loss = 0.0
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{CONFIG['epochs']} [Train]", leave=False)

        for batch in train_pbar:
            sensor_data = batch['sensor_data'].to(DEVICE)
            positions = batch['position'].to(DEVICE)

            # Flow Matching loss
            loss = compute_flow_matching_loss(model, sensor_data, positions)

            # Backward
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            scheduler.step()

            train_loss += loss.item()
            train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})

        train_loss /= len(train_loader)

        # ========== Validation ==========
        model.eval()
        val_loss = 0.0
        val_position_error = 0.0

        with torch.no_grad():
            for batch in tqdm(val_loader, desc=f"Epoch {epoch+1}/{CONFIG['epochs']} [Val]", leave=False):
                sensor_data = batch['sensor_data'].to(DEVICE)
                positions = batch['position'].to(DEVICE)

                # Flow Matching loss
                loss = compute_flow_matching_loss(model, sensor_data, positions)
                val_loss += loss.item()

                # Position error (using sampling)
                pred_positions = model.sample(sensor_data, n_steps=CONFIG['inference_steps'])
                error = torch.norm(pred_positions - positions, dim=1).mean()
                val_position_error += error.item()

        val_loss /= len(val_loader)
        val_position_error /= len(val_loader)

        print(f"Epoch {epoch+1:3d} | "
              f"Train Loss: {train_loss:.4f} | "
              f"Val Loss: {val_loss:.4f} | "
              f"Val Pos Error: {val_position_error:.4f}")

        # Save best model
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            model_dir = Path(__file__).parent.parent / 'models'
            model_dir.mkdir(exist_ok=True)

            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'val_loss': val_loss,
                'val_position_error': val_position_error,
                'config': CONFIG,
            }, model_dir / 'flow_matching_best.pt')

    print("\n[6/6] í•™ìŠµ ì™„ë£Œ!")
    print(f"  ìµœê³  Val Loss: {best_val_loss:.4f}")
    print(f"  ëª¨ë¸ ì €ì¥: models/flow_matching_best.pt")

    # ========== Test Sampling Speed ==========
    print("\n" + "=" * 70)
    print("âš¡ Inference Speed Test")
    print("=" * 70)

    model.eval()
    test_batch = next(iter(val_loader))
    sensor_data = test_batch['sensor_data'][:4].to(DEVICE)

    import time

    for n_steps in [1, 2, 5, 10]:
        start = time.time()
        with torch.no_grad():
            for _ in range(100):
                _ = model.sample(sensor_data, n_steps=n_steps)
        end = time.time()

        avg_time = (end - start) / 100 * 1000  # ms
        print(f"  {n_steps} steps: {avg_time:.2f} ms/batch (4 samples)")

    print("\n" + "=" * 70)
    print("âœ… Flow Matching í•™ìŠµ ì™„ë£Œ!")
    print("=" * 70)
    print(f"""
ğŸ“Š ìµœì¢… ê²°ê³¼:
  Val Loss: {best_val_loss:.4f}
  ëª¨ë¸: models/flow_matching_best.pt

ğŸ”¥ ë…ì°½ì„±:
  âœ… ì§€ìê¸° ê¸°ë°˜ ì¸ë„ì–´ í¬ì§€ì…”ë‹ì— Flow Matching ì²« ì ìš©
  âœ… 1-2 step inferenceë¡œ ì‹¤ì‹œê°„ ê°€ëŠ¥
  âœ… Conditional generationìœ¼ë¡œ ì„¼ì„œ â†’ ìœ„ì¹˜ ë§¤í•‘

ğŸ¯ ë‹¤ìŒ ë‹¨ê³„:
  1. í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì„±ëŠ¥ ì¸¡ì •
  2. LSTM/Transformer ë² ì´ìŠ¤ë¼ì¸ê³¼ ë¹„êµ
  3. ë…¼ë¬¸ ì‘ì„± (ì™„ì „íˆ ìƒˆë¡œìš´ ì ‘ê·¼ë²•!)
""")

if __name__ == '__main__':
    train()
