#!/usr/bin/env python3
"""
Grid 3më¡œ ì¬í‰ê°€
"""
import torch
import numpy as np
from pathlib import Path
from torch.utils.data import DataLoader
from tqdm import tqdm
from train_flow_matching import FlowMatchingDataset, CONFIG
from model import FlowMatchingLocalization

print("="*70)
print("ğŸ“Š Grid 3më¡œ ì¬í‰ê°€")
print("="*70)

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ë°ì´í„° ë¡œë“œ
BASE_DIR = Path(__file__).resolve().parent
data_dir = BASE_DIR / 'processed_data_flow_matching'
states_test = np.load(data_dir / 'states_test.npy', allow_pickle=True)
traj_test = np.load(data_dir / 'trajectories_test.npy', allow_pickle=True)

test_dataset = FlowMatchingDataset(states_test, traj_test, augment=False)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

print(f"\nTest ìƒ˜í”Œ: {len(test_dataset):,}ê°œ")

# ëª¨ë¸ ë¡œë“œ
model = FlowMatchingLocalization(
    sensor_dim=6, position_dim=2, d_model=256,
    encoder_layers=4, velocity_layers=4, n_heads=8, dropout=0.1
).to(DEVICE)

checkpoint = torch.load(BASE_DIR.parent / 'models' / 'flow_matching_best.pt')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Grid í¬ê¸°ë“¤ í…ŒìŠ¤íŠ¸
grid_sizes_meters = [0.9, 1.5, 2.0, 3.0, 5.0]
print(f"\në‹¤ì–‘í•œ Grid í¬ê¸°ë¡œ í‰ê°€:")

for grid_m in grid_sizes_meters:
    # ì •ê·œí™”ëœ grid í¬ê¸° (ê±´ë¬¼ ë²”ìœ„ 85.5m, ì •ê·œí™” -1~1)
    grid_normalized = grid_m / 85.5 * 2

    correct_normal = 0
    correct_topk = 0
    total = 0

    with torch.no_grad():
        for batch in tqdm(test_loader, desc=f"Grid {grid_m}m", leave=False):
            sensor_data = batch['sensor_data'].to(DEVICE)
            positions = batch['position'].to(DEVICE)

            # ì¼ë°˜ ìƒ˜í”Œë§
            pred_pos = model.sample(sensor_data, n_steps=10)
            error = torch.norm(pred_pos - positions, dim=1)
            correct_normal += (error <= grid_normalized).sum().item()

            # Top-5 ìƒ˜í”Œë§
            best_pos, topk_positions, topk_scores = model.sample_topk(
                sensor_data, n_samples=10, k=5, n_steps=10
            )

            # 5ê°œ ì¤‘ í•˜ë‚˜ë¼ë„ ë§ìœ¼ë©´ ì •ë‹µ
            for b in range(len(positions)):
                target_pos = positions[b]
                candidates = topk_positions[b]  # (5, 2)
                errors = torch.norm(candidates - target_pos, dim=1)
                if (errors <= grid_normalized).any():
                    correct_topk += 1

            total += len(positions)

    acc_normal = correct_normal / total * 100
    acc_topk = correct_topk / total * 100

    print(f"\n  ğŸ“ Grid {grid_m}m (ì •ê·œí™”: {grid_normalized:.4f}):")
    print(f"     ì¼ë°˜ ìƒ˜í”Œë§: {acc_normal:.2f}% ({correct_normal}/{total})")
    print(f"     Top-5 í›„ë³´: {acc_topk:.2f}% ({correct_topk}/{total})")

print("\n" + "="*70)
print("âœ… ì¬í‰ê°€ ì™„ë£Œ!")
print("="*70)
